{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de multi-etiquetas de vídeo\n",
    "\n",
    "Este notebook corresponde a atividade da seção 3.6 no livro do curso. Esta atividade mostra de forma simples, como implementar um programa para realizar classificação de multi-etiquetas de vídeo. Para isso, é implementado um modelo de rede neural que agregar features de diferentes modalidades para realizar multiclassificação.\n",
    "\n",
    "Na pasta \"dataset\" existe uma coleção de tabelas csv que contém features (embeddings) audio-visuais de 50 mil vídeos que foram extraídos de uma parte do dataset Youtube8M. Os embeddings visuais foram extraídas da última camada da rede Inception-Resnet-v2 pré-treinada com o dataset ImageNet. Já as features de áudio foram extraídas da última camada da rede Audio-VGG pré-treinada com o dataset AudioSet. A imagem abaixo ilustra o todo o processo de classificação, nesta atividade apenas o processo de agregação de features é implementado.  \n",
    "\n",
    "\n",
    "<img src=\"images/multi_modal_arq.png\" width=\"700px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Pacotes\n",
    "\n",
    "Execute o bloco abaixo para importar os pacotes necessarios. \n",
    "\n",
    "- [tensorflow](https://www.tensorflow.org/) um framework para deep learning\n",
    "- [numpy](www.numpy.org) pacote de bilbiotecas para computação científica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#códigos locais com funções necessárias para a atividade\n",
    "from read_batch import *\n",
    "from evaluate import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Modelo para Multiclassificação\n",
    "\n",
    "Nesta etapa é definido um modelo para multiclassificação. No código abaixo, a função \"build_deep_fully_network\" recebe como parâmetro a quantidade de features e número de classes do problema e cria uma uma rede MLP com duas camadas escondidas. A primeira camada tem 2000 unidades, enquanto a segunda tem 3200 unidades. Para a função de perda é usada a função de entropia cruzada com logist, que é a mais indicada para esse tipo de tarefa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_fully_network(num_features, num_classes):\n",
    "    \n",
    "    # Placeholders\n",
    "    X_ = tf.placeholder(dtype=tf.float32, shape=[None, num_features])\n",
    "    Y_ = tf.placeholder(dtype=tf.float32, shape=[None, num_classes])\n",
    "    \n",
    "    kernel_initializer = tf.contrib.layers.xavier_initializer()\n",
    "    \n",
    "    #camada escondida 1\n",
    "    layer1 = tf.layers.dense(X_, 2000, activation=tf.nn.relu, kernel_initializer=kernel_initializer)\n",
    "    \n",
    "    #camada escondida 2\n",
    "    layer2 = tf.layers.dense(layer1, 3200, activation=tf.nn.relu, kernel_initializer=kernel_initializer)  \n",
    "    \n",
    "    #saída\n",
    "    logits = tf.layers.dense(layer2, num_classes, activation=None, kernel_initializer=kernel_initializer)\n",
    "    \n",
    "    #Loss function\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=Y_))\n",
    "\n",
    "    #Optimizer\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "    \n",
    "    output = tf.nn.sigmoid(logits)\n",
    "    \n",
    "    #Acc (não usado nessa atividade)\n",
    "    correct_prediction = tf.equal(tf.round(output), Y_)\n",
    "    acc = evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    return opt, loss, acc, output, X_, Y_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Iniciando o Tensorflow\n",
    "\n",
    "O código abaixo inicia uma sessão no TensorFlow. Em seguida, é definida a quantidade de features, 1152 (1024 embeddings visuais + 128 embeddings auditivos). O número de classes de vídeo utilizado é a mesma do YouTube8M, 3862. Por fim, o gráfo de computação é carregado pela chamada da função \"build_deep_fully_network\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iniciando\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "num_features = 1152\n",
    "num_classes = 3862\n",
    "\n",
    "#construindo o modelo de rede\n",
    "opt, loss, acc, output, X_, Y_ = build_deep_fully_network(num_features, num_classes)\n",
    "\n",
    "# inicializando as variveis do tensorflow\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Treinamento\n",
    "\n",
    "Nessa etapa o modelo instanciado é treinado com os dados do dataset. Caso a máquina de execução não tenha uma GPU, é possível carregar o modelo pré-treinado ao setar a variavel load_save como True. Caso contrário, o modelo é treinado com 10 épocas. No fim de cada época o estado atual do modelo é avaliado, caso o resultado seja o melhor encontrado, os pesos são salvos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/train_0.508937495467.ckpt\n",
      "Avaliando o modelo carregado:\n",
      "evaluation: gap 0.5089374954672038 hit1 0.7886026258161525 hit5 0.8854712240016954 hit20 0.9256052395224688\n"
     ]
    }
   ],
   "source": [
    "load_save = True\n",
    "\n",
    "# restaura pesos salvos, \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if load_save:\n",
    "    saver.restore(sess, \"save/train_0.508937495467.ckpt\")\n",
    "    \n",
    "    print(\"Avaliando o modelo carregado:\")\n",
    "    #test loop com break interno\n",
    "    while True:\n",
    "        \n",
    "        #obtem um batch com: id do batch, vetor de labels e features\n",
    "        batch_id, labels, features = get_next_val_batch()\n",
    "        \n",
    "        #caso o id seja menor que 0, significa que todos os batchs foram usados\n",
    "        if batch_id < 0:\n",
    "            break\n",
    "        \n",
    "        #alimentando o modelo com os dados e avaliando os resultados \n",
    "        feed_dict={X_: features, Y_: labels}\n",
    "        result = sess.run(output, feed_dict=feed_dict)\n",
    "        register_batch_evaluation(labels, num_classes, result)\n",
    "    \n",
    "    #no termino do loop, os resultados são impressos na tela\n",
    "    gap, hit1, hit5, hit20 = get_global_evaluation_result()\n",
    "    print(\"evaluation: gap\", gap, \"hit1\", hit1, \"hit5\", hit5, \"hit20\", hit20)\n",
    "\n",
    "\n",
    "# caso contrário, inicia o treinamento    \n",
    "else:\n",
    "    num_epochs = 10\n",
    "    best_gap = 0\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        #training loop\n",
    "        while True:\n",
    "            #obtem um batch com: id do batch, vetor de labels e features\n",
    "            batch_num, labels, features = get_next_train_batch()\n",
    "            \n",
    "            #caso o id seja menor que 0, significa que todos os batchs foram usados\n",
    "            if batch_num < 0:\n",
    "                break\n",
    "            \n",
    "            feed_dict={X_: features, Y_: labels}\n",
    "            _, loss = sess.run([opt,loss], feed_dict=feed_dict)\n",
    "\n",
    "            #print(\"epoch\", epoch,\"batch id\", batch_num,\"loss:\", loss)\n",
    "\n",
    "        #test loop\n",
    "        while True:\n",
    "            #obtem um batch com: id do batch, vetor de labels e features\n",
    "            batch_num, labels, features = get_next_val_batch()\n",
    "            \n",
    "            #caso o id seja menor que 0, significa que todos os batchs foram usados\n",
    "            if batch_num < 0:\n",
    "                break\n",
    "            \n",
    "            #alimentando o modelo com os dados e avaliando os resultados \n",
    "            feed_dict={X_: features, Y_: labels}\n",
    "            result = sess.run(output, feed_dict=feed_dict)\n",
    "            register_batch_evaluation(labels, num_classes, result)\n",
    "        \n",
    "        #no termino do loop, os resultados são impressos na tela\n",
    "        gap, hit1, hit5, hit20 = get_global_evaluation_result()\n",
    "        print(\"validation: epoch\", epoch, \"- gap\", gap, \"hit1\", hit1, \"hit5\", hit5, \"hit20\", hit20)\n",
    "        \n",
    "        #apaga os registros da avaliação atual para realizar a avaliacao da próxima época\n",
    "        clear_registered_evaluations()\n",
    "        \n",
    "        #melhor resultado é salvo\n",
    "        if gap > best_gap:\n",
    "            best_gap = gap\n",
    "            save_path = saver.save(sess, \"save/train_\"+str(best_gap)+\".ckpt\")\n",
    "            print(\"melhor modelo salvo em ...\", save_path)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Classificando vídeos\n",
    "\n",
    "Nesta etapa o modelo é usado para classifiacar os vídeos. Nesse experimento usamos apenas as 5 maiores ativações da rede para atribuir até 5 tags ao vídeo. A função \"show_top5_labels_info\" definida no código abaixo, filtra as top5 labels e exibe suas informações. O parâmetro threshold define um limiar de corte para excluir ativações muito baixas entre as top5 selecionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top5_labels_info(num_classes, output, threshold):\n",
    "    \n",
    "    #vetor de features e labels \n",
    "    sample_features = output[0]\n",
    "    labels_id = np.arange(num_classes)\n",
    "    \n",
    "    #os vetores são ordenados de forma decrescente pelo valor das ativações\n",
    "    top5_labels = labels_id[np.argsort(-sample_features)][:5]\n",
    "    top5_features = sample_features[np.argsort(-sample_features)][:5]\n",
    "    \n",
    "    #filtragem das top5 labels\n",
    "    for index, label in enumerate(top5_labels):\n",
    "        if top5_features[index] > threshold:\n",
    "            show_meta_data(label)\n",
    "        else:\n",
    "            break\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo seleciona os três primeiros vídeos de cada batch e mostra os metadados das top5 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1 video 1 metadata:\n",
      "- label id: 0 name: Game wiki: https://en.wikipedia.org/wiki/Game\n",
      "- label id: 23 name: Smartphone wiki: https://en.wikipedia.org/wiki/Smartphone\n",
      "- label id: 21 name: Mobile phone wiki: https://en.wikipedia.org/wiki/Mobile_phone\n",
      "- label id: 72 name: Skateboard wiki: https://en.wikipedia.org/wiki/Skateboard\n",
      "- label id: 5 name: Cartoon wiki: https://en.wikipedia.org/wiki/Cartoon\n",
      "\n",
      "\n",
      "batch 1 video 2 metadata:\n",
      "- label id: 62 name: Machine wiki: https://en.wikipedia.org/wiki/Machine\n",
      "- label id: 1354 name: The Hobbit (film series) wiki: https://en.wikipedia.org/wiki/The_Hobbit_(film_series)\n",
      "- label id: 8 name: Dance wiki: https://en.wikipedia.org/wiki/Dance\n",
      "- label id: 14 name: Music video wiki: https://en.wikipedia.org/wiki/Music_video\n",
      "- label id: 575 name: Forza (series) wiki: https://en.wikipedia.org/wiki/Forza_(series)\n",
      "\n",
      "\n",
      "batch 1 video 3 metadata:\n",
      "- label id: 0 name: Game wiki: https://en.wikipedia.org/wiki/Game\n",
      "- label id: 133 name: Comedy (drama) wiki: https://en.wikipedia.org/wiki/Comedy_(drama)\n",
      "- label id: 337 name: Resident Evil wiki: https://en.wikipedia.org/wiki/Resident_Evil\n",
      "- label id: 957 name: Car wash wiki: https://en.wikipedia.org/wiki/Car_wash\n",
      "- label id: 244 name: Pony wiki: https://en.wikipedia.org/wiki/Pony\n"
     ]
    }
   ],
   "source": [
    "#cada vez que esse bloco é executado, um batch com novos vídeos é carregado\n",
    "batch_id, _, features = get_next_train_batch()\n",
    "\n",
    "video_features1 = np.zeros((1,num_features))\n",
    "video_features2 = np.zeros((1,num_features))\n",
    "video_features3 = np.zeros((1,num_features))\n",
    "\n",
    "#obtendo as features de cada vídeo\n",
    "video_features1[0] = features[0,:]\n",
    "video_features2[0] = features[1,:]\n",
    "video_features3[0] = features[2,:]\n",
    "\n",
    "result_video1 = sess.run(output, feed_dict={X_: video_features1})\n",
    "print(\"batch\",batch_id, \"video 1 metadata:\")\n",
    "show_top5_labels_info(num_classes, result_video1, 0.)\n",
    "\n",
    "result_video2 = sess.run(output, feed_dict={X_: video_features2})\n",
    "print(\"\\n\\nbatch\",batch_id, \"video 2 metadata:\")\n",
    "show_top5_labels_info(num_classes, result_video2, 0.)\n",
    "\n",
    "result_video3 = sess.run(output, feed_dict={X_: video_features3})\n",
    "print(\"\\n\\nbatch\",batch_id, \"video 3 metadata:\")\n",
    "show_top5_labels_info(num_classes, result_video3, 0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
